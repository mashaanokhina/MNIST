#import libraries
import pandas as pd
import numpy as nm
import matplotlib.pyplot as plt
import tensorflow as tf
#load data, separate our features and labels
from keras.datasets import mnist
(train_images, train_labels),(test_images, test_labels)=mnist.load_data()
train_images=train_images.reshape((60000,28,28,1))
train_images=train_images.astype('float32')/255
print('train_images.shape:',train_images.shape)
test_images=test_images.reshape((10000,28,28,1))
test_images=test_images.astype('float32')/255
print('test_images.shape:',test_images.shape)
from keras.utils import to_categorical
train_labels=to_categorical(train_labels)
test_labels=to_categorical(test_labels)

#Compeling a model
from keras import layers
from keras import models
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
model=models.Sequential()
model.add(layers.Conv2D(32,(3,3),  padding='same', activation='relu', input_shape = (28,28,1)))
model.add(MaxPooling2D(pool_size=(2,2),strides=2))
model.add(layers.Conv2D(32,(3,3), padding='same', activation='relu'))
model.add(layers.MaxPooling2D((2,2), strides=2))
model.add(layers.Conv2D(64,(3,3), padding='same', activation='relu'))
model.add(Dropout(0.2))
model.add(layers.Flatten())
model.add(layers.Dense(64,activation = 'relu'))
model.add(layers.Dense(10, activation= 'softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

print(model.summary())

history = model.fit(train_images, train_labels, epochs=5, batch_size = 64, validation_split=0.2)
model.evaluate(test_images,test_labels)

epoch_nums = range(1,6)
training_loss = history.history["loss"]
validation_loss = history.history["val_loss"]
plt.plot(epoch_nums, training_loss)
plt.plot(epoch_nums, validation_loss)
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['training', 'validation'], loc='upper right')
plt.show()
print('end')
